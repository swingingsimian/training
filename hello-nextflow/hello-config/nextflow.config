/*
 * Pipeline parameters
 */

// Can over-ride these on cmdline individually or with params file:
// nextflow run main.nf -profile my_laptop -params-file demo-params.json


params {
    // Primary input (file of input files, one per line)
    reads_bam        = "${projectDir}/data/sample_bams.txt"

    // Output directory
    outdir           = 'results_genomics'

    // Accessory files
    reference        = "${projectDir}/data/ref/ref.fasta"
    reference_index  = "${projectDir}/data/ref/ref.fasta.fai"
    reference_dict   = "${projectDir}/data/ref/ref.dict"
    intervals        = "${projectDir}/data/ref/intervals.bed"

    // Base name for final output file
    cohort_name      = "family_trio"
}

// Used to test params file does actually over-ride these defaults
// params {
//     // Primary input (file of input files, one per line)
//     reads_bam        = null

//     // Output directory
//     outdir           = null

//     // Accessory files
//     reference        = null
//     reference_index  = null
//     reference_dict   = null
//     intervals        = null

//     // Base name for final output file
//     cohort_name      = "my_cohort"
// }


// // Primary input (file of input files, one per line)
// params.reads_bam = "${projectDir}/data/sample_bams.txt"

// // Output directory
// params.outdir    = 'results_genomics'

// // Accessory files
// params.reference        = "${projectDir}/data/ref/ref.fasta"
// params.reference_index  = "${projectDir}/data/ref/ref.fasta.fai"
// params.reference_dict   = "${projectDir}/data/ref/ref.dict"
// params.intervals        = "${projectDir}/data/ref/intervals.bed"

// // Base name for final output file
// params.cohort_name = "family_trio"





// docker.enabled = true
// conda.enabled = true


profiles {
    docker_on {
        docker.fixOwnership = true
        docker.enabled = true
    }
    conda_on {
        conda.enabled = true
    }

    local_exec {
        process.executor = 'local'
    }
    slurm_exec {
        process.executor = 'slurm'
    }

    my_laptop {
        process.executor = 'local'
        docker.enabled = true
    }
    univ_hpc {
        process.executor = 'slurm'
        conda.enabled = true

        // These maybe enforced your compute cluster
        process.resourceLimits = [
            memory: 750.GB,
            cpus: 200,
            time: 30.d
        ]
        // More configs for different hpcs can be found here https://nf-co.re/configs/
    }

    // Instead of a separate demo params file the user has to know about
    demo {
        // Primary input (file of input files, one per line)
        params.reads_bam        = "data/sample_bams.txt"

        // Output directory
        params.outdir           = 'results_genomics'

        // Accessory files
        params.reference        = "data/ref/ref.fasta"
        params.reference_index  = "data/ref/ref.fasta.fai"
        params.reference_dict   = "data/ref/ref.dict"
        params.intervals        = "data/ref/intervals.bed"

        // Base name for final output file
        params.cohort_name      = "family_trio"
    }
}

// process {
//     // defaults for all processes
//     cpus = 2
//     memory = 4.GB

//     // Tip - You can check the number of CPUs allocated to a given process by looking at the .command.run log in its work directory. 
//     // There will be a function called nxf_launch() that includes the command docker run—i—-CPU 1024, where --cpu-shares refers to 
//     // the CPU time given to this process' tasks. Setting one task's cpu_share to 512 and another to 1024 means that the second task 
//     // will get double the amount of CPU time as the first.
// }
// process {
//     executor = 'slurm'
// }

// optimised based on report output
process {
    // defaults for all processes
    cpus = 2
    memory = 2.GB
    // allocations for a specific process
    withName: 'GATK_JOINTGENOTYPING' {
        cpus = 4
    }
}
// a lot more can be done with dynamic retry logic, see here https://training.nextflow.io/basic_training/debugging/#dynamic-resources-allocation

// resource profiling to help optimise resource spec
// nextflow run main.nf -profile my_laptop -with-report report-config-1.html
// For some reason samtool was not plotted in the memory plot?
